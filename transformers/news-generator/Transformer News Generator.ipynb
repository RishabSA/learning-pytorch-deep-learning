{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyO2ZFCwvQ2fUDXJkFTQKLaV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jR3lOpc41qD4","executionInfo":{"status":"ok","timestamp":1739796390466,"user_tz":300,"elapsed":2500,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}},"outputId":"7bf76e6f-2981-43d3-be27-4ac2cb5c5f3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}],"source":["!pip install datasets transformers"]},{"cell_type":"code","source":["import math\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.auto import tqdm\n","\n","from datasets import load_dataset\n","from transformers import AutoTokenizer\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yuAkr42M11ag","executionInfo":{"status":"ok","timestamp":1739799641157,"user_tz":300,"elapsed":5,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}},"outputId":"28e5d4da-83ce-43d8-83fc-f83ceb3bf284"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["dataset = load_dataset(\"ag_news\", split=\"train\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hWgVSyNE125H","executionInfo":{"status":"ok","timestamp":1739796397535,"user_tz":300,"elapsed":1981,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}},"outputId":"24067125-9257-491a-fc3a-3abac4cf2b20"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["len(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M1XEyU8F2UGz","executionInfo":{"status":"ok","timestamp":1739796397535,"user_tz":300,"elapsed":6,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}},"outputId":"383e76a6-a3cc-4652-d505-61e642461912"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["120000"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["def split_headline_body(example):\n","  # Try splitting using \" - \" if present, else use the first sentence as headline.\n","  if \" - \" in example[\"text\"]:\n","      headline, body = example[\"text\"].split(\" - \", 1)\n","  else:\n","      parts = example[\"text\"].split(\".\")\n","      headline = parts[0]\n","      body = \".\".join(parts[1:]).strip()\n","  example[\"headline\"] = headline.strip()\n","  example[\"body\"] = body.strip() if body.strip() else headline.strip()\n","  return example"],"metadata":{"id":"hwy6o7832LL1","executionInfo":{"status":"ok","timestamp":1739796397535,"user_tz":300,"elapsed":5,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["dataset = dataset.map(split_headline_body)"],"metadata":{"id":"mHG_smNK2NId","executionInfo":{"status":"ok","timestamp":1739796397535,"user_tz":300,"elapsed":4,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token"],"metadata":{"id":"ePAs2nw47dS4","executionInfo":{"status":"ok","timestamp":1739796397805,"user_tz":300,"elapsed":274,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class NewsDataset:\n","  def __init__(self, dataset, tokenizer, max_input_length=32, max_output_length=128):\n","    self.dataset = dataset\n","    self.tokenizer = tokenizer\n","    self.max_input_length = max_input_length\n","    self.max_output_length = max_output_length\n","\n","  def __len__(self):\n","    return len(self.dataset)\n","\n","  def __getitem__(self, idx):\n","    sample = self.dataset[idx]\n","    headline = sample[\"headline\"]\n","    body = sample[\"body\"]\n","\n","    input_enc = self.tokenizer(headline,\n","                                truncation=True,\n","                                max_length=self.max_input_length,\n","                                return_tensors=\"pt\")\n","    target_enc = self.tokenizer(body,\n","                                truncation=True,\n","                                max_length=self.max_output_length,\n","                                return_tensors=\"pt\")\n","\n","    # Remove the extra batch dimension.\n","    input_ids = input_enc.input_ids.squeeze(0)\n","    target_ids = target_enc.input_ids.squeeze(0)\n","\n","    return {\"input_ids\": input_ids, \"target_ids\": target_ids}\n","\n","news_dataset = NewsDataset(dataset, tokenizer)"],"metadata":{"id":"4hN8tlYp2VEb","executionInfo":{"status":"ok","timestamp":1739796397806,"user_tz":300,"elapsed":6,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def collate_fn(batch):\n","  input_ids = [item[\"input_ids\"] for item in batch]\n","  target_ids = [item[\"target_ids\"] for item in batch]\n","  input_ids = nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n","  target_ids = nn.utils.rnn.pad_sequence(target_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n","  return input_ids, target_ids"],"metadata":{"id":"MgbcgfIH2lOq","executionInfo":{"status":"ok","timestamp":1739796397806,"user_tz":300,"elapsed":5,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["dataloader = DataLoader(news_dataset,\n","                        batch_size=128,\n","                        shuffle=True,\n","                        collate_fn=collate_fn)"],"metadata":{"id":"oD86Q1cE2z6P","executionInfo":{"status":"ok","timestamp":1739796397806,"user_tz":300,"elapsed":5,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Positional Encoding\n","class PositionalEncoding(nn.Module):\n","  def __init__(self,\n","               d_model: int,\n","               dropout: float = 0.1,\n","               max_length: int = 5000):\n","    \"\"\"\n","    d_model: dimensions of the embeddings (number of values in each embedding vector)\n","    dropout: probability of dropout\n","    max_length: max length of a sequence\n","    \"\"\"\n","    super().__init__()\n","\n","    self.dropout = nn.Dropout(p=dropout)\n","\n","    pe = torch.zeros(max_length, d_model) # (max_length, d_model)\n","    # Create position column\n","    k = torch.arange(0, max_length).unsqueeze(dim=1)\n","    # Use the log version of the function for positional encodings\n","    div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n","\n","    # Use sine for the even indices and cosine for the odd indices\n","    pe[:, 0::2] = torch.sin(k * div_term)\n","    pe[:, 1::2] = torch.cos(k * div_term)\n","\n","    pe = pe.unsqueeze(dim=0) # Add the batch dimension\n","\n","    # We use a buffer because the positional encoding is fixed and not a model paramter that we want to be updated during backpropagation.\n","    self.register_buffer(\"pe\", pe) # Buffers are saved with the model state and are moved to the correct device\n","\n","  def forward(self, x):\n","    # x shape: (batch_size, seq_length, d_model)\n","    # Add the positional encoding to the embeddings that are passed in\n","    x += self.pe[:, :x.size(1)]\n","    return self.dropout(x)"],"metadata":{"id":"8t1Ezz-H23T_","executionInfo":{"status":"ok","timestamp":1739796397806,"user_tz":300,"elapsed":4,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class TransformerNewsGenerator(nn.Module):\n","  def __init__(self,\n","               vocab_size,\n","               pad_token_id,\n","               d_model=512,\n","               n_head=8,\n","               n_layers=3,\n","               dim_ffn=2048,\n","               dropout=0.1,\n","               max_seq_length=512):\n","    super().__init__()\n","    self.d_model = d_model\n","    self.pad_token_id = pad_token_id\n","\n","    self.embedding = nn.Embedding(vocab_size, d_model)\n","    self.pos_encoder = PositionalEncoding(d_model, dropout, max_seq_length)\n","    self.pos_decoder = PositionalEncoding(d_model, dropout, max_seq_length)\n","    self.transformer = nn.Transformer(d_model=d_model,\n","                                      nhead=n_head,\n","                                      num_encoder_layers=n_layers,\n","                                      num_decoder_layers=n_layers,\n","                                      dim_feedforward=dim_ffn,\n","                                      dropout=dropout)\n","    self.fc_out = nn.Linear(d_model, vocab_size)\n","\n","  def generate_square_subsequent_mask(self, sz):\n","    # Generate the target mask to prevent the decoder from peeking at future target values during training\n","    mask = torch.triu(torch.ones(sz, sz), diagonal=1)\n","    mask = mask.masked_fill(mask == 1, float('-inf'))\n","    return mask\n","\n","  def forward(self, src, trg):\n","    trg_seq_len = trg.size(1)\n","    trg_mask = self.generate_square_subsequent_mask(trg_seq_len).to(trg.device)\n","\n","    # Create key padding masks\n","    src_key_padding_mask = (src == self.pad_token_id)\n","    trg_key_padding_mask = (trg == self.pad_token_id)\n","\n","    # Embedding and Positional Encodings\n","    src_emb = self.embedding(src) * math.sqrt(self.d_model)\n","    src_emb = self.pos_encoder(src_emb)\n","    src_emb = src_emb.transpose(0, 1) # We want a shape of (seq_length, batch_size, d_model)\n","\n","    trg_emb = self.embedding(trg) * math.sqrt(self.d_model)\n","    trg_emb = self.pos_decoder(trg_emb)\n","    trg_emb = trg_emb.transpose(0, 1)\n","\n","    output = self.transformer(src_emb,\n","                              trg_emb,\n","                              tgt_mask=trg_mask,\n","                              src_key_padding_mask=src_key_padding_mask,\n","                              tgt_key_padding_mask=trg_key_padding_mask)\n","\n","    # (seq_len, batch, d_model) -> (batch, seq_len, d_model)\n","    output = output.transpose(0, 1)\n","\n","    output += torch.randn_like(output) * 0.001\n","    logits = self.fc_out(output)\n","    return logits"],"metadata":{"id":"StF98N_U3MLF","executionInfo":{"status":"ok","timestamp":1739796397806,"user_tz":300,"elapsed":4,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["vocab_size = len(tokenizer)\n","model = TransformerNewsGenerator(vocab_size=vocab_size, pad_token_id=tokenizer.pad_token_id).to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iuQQwW6J5KEn","executionInfo":{"status":"ok","timestamp":1739799662842,"user_tz":300,"elapsed":870,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}},"outputId":"751b955d-9289-443f-b494-bae602099f76"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["lr = 0.0005\n","loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n","optimizer = optim.AdamW(params=model.parameters(), lr=lr)"],"metadata":{"id":"jnBVz7NS5TK9","executionInfo":{"status":"ok","timestamp":1739799664071,"user_tz":300,"elapsed":70,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["epochs = 10\n","clip = 1\n","model.train()\n","\n","best_valid_loss = float('inf')\n","model_path = \"next_word_pred_model.pt\"\n","\n","if os.path.exists(model_path):\n","  print(f\"Loading model from {model_path}...\")\n","  model.load_state_dict(torch.load(model_path, map_location=device))\n","else:\n","  print(\"No saved model found. Starting training...\")\n","\n","  # Training\n","  for epoch in tqdm(range(epochs), desc=\"Training Progress\", colour=\"#00ff00\"):\n","    epoch_loss = 0\n","\n","    pbar = tqdm(dataloader, total=len(dataloader), desc=f\"Epoch {epoch+1} Progress\", colour=\"#005500\")\n","    for i, (src, trg) in enumerate(pbar):\n","      src, trg = src.to(device), trg.to(device)\n","\n","      # Forward pass\n","      # Pass in the full target sequence without the <eos> token, and in the model we use the target mask to prevent it from peeking at future values\n","      logits = model(src, trg[:,:-1]) # Remove <eos> token because we want to predict it ourselves\n","\n","      # Expected target\n","      expected_output = trg[:,1:] # Remove <bos> token because the <eos> was not generated in the logits, so we need to remove it to properly compare\n","\n","      # Calculate the loss\n","      # contiguous() flattens so that every token position in every sequence is treated as an individual prediction.\n","      loss = loss_fn(logits.reshape(-1, vocab_size), expected_output.reshape(-1))\n","      epoch_loss += loss.item()\n","\n","      optimizer.zero_grad()\n","\n","      # Backpropagation\n","      loss.backward()\n","\n","      # Gradient Clipping\n","      torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","\n","      # Optimizer Step\n","      optimizer.step()\n","\n","      pbar.set_postfix(loss=loss.item()) # Update the loss on the tqdm progress bar\n","\n","    message = f\"Epoch: {epoch + 1} | Loss: {epoch_loss / len(dataloader)}\"\n","\n","    if epoch_loss / len(dataloader) < best_valid_loss:\n","      best_valid_loss = epoch_loss / len(dataloader)\n","      torch.save(model.state_dict(), model_path)\n","      message += \" --> STORED\"\n","\n","    print(message)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gCBKy4aR5bCF","executionInfo":{"status":"ok","timestamp":1739799666106,"user_tz":300,"elapsed":355,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}},"outputId":"336dca31-e5ca-4ca1-d1ec-7588cc746ab5"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading model from next_word_pred_model.pt...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-19-59e11059cd0b>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path, map_location=device))\n"]}]},{"cell_type":"code","source":["def generate_text(model, tokenizer, headline, max_length=50):\n","  model.eval()\n","  with torch.no_grad():\n","    # Tokenize the input headline.\n","    input_enc = tokenizer(headline, return_tensors=\"pt\")\n","    input_ids = input_enc.input_ids.to(device)\n","\n","    # Start the decoder with the EOS token\n","    generated = torch.tensor([[tokenizer.eos_token_id]], device=device)\n","\n","    for i in range(max_length):\n","      outputs = model(input_ids, generated)\n","\n","      # Get the logits for the last time step\n","      next_token_logits = outputs[:, -1, :]\n","      next_token = torch.argmax(next_token_logits, dim=-1).unsqueeze(0)\n","      generated = torch.cat((generated, next_token), dim=1)\n","      if next_token.item() == tokenizer.eos_token_id:\n","        break\n","    # Decode and clean up the generated tokens.\n","    generated_text = tokenizer.decode(generated.squeeze(), skip_special_tokens=True)\n","  return generated_text"],"metadata":{"id":"GDqEL2qa68JW","executionInfo":{"status":"ok","timestamp":1739799670535,"user_tz":300,"elapsed":78,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["headline_example = \"Breaking News: Russia has officially started the war\"\n","generated_article = generate_text(model, tokenizer, headline_example)\n","\n","print(\"Headline:\", headline_example)\n","print(\"Generated Article:\\n\", generated_article)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NSUGwbu_7Mmz","executionInfo":{"status":"ok","timestamp":1739799722513,"user_tz":300,"elapsed":373,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}},"outputId":"8c0f12c6-6729-4957-f185-961175670de7"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Headline: Breaking News: Russia has officially started the war\n","Generated Article:\n","  President Vladimir Putin has officially announced the war on terror and the war in Iraq. The war, the Kremlin has announced that Russia #39;s president has started withdrawing his country #39;s war on terror.  quot;terror and the basis\n"]}]},{"cell_type":"code","source":["#@title News Generator\n","headline_input = \"Russia has officially declared war\" #@param \"\"\n","\n","generated_article = generate_text(model, tokenizer, headline_input, max_length=50)\n","\n","print(\"Headline:\", headline_example)\n","print(\"Generated Article:\\n\", generated_article)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qxy8PtADJ20b","executionInfo":{"status":"ok","timestamp":1739800006953,"user_tz":300,"elapsed":439,"user":{"displayName":"Rishab Alagharu","userId":"00430901930976372567"}},"outputId":"0839d833-df8f-45a5-f47e-46b8e3f46a0c"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Headline: Breaking News: Russia has officially started the war\n","Generated Article:\n","  President Vladimir Putin has officially announced war-torn Chechnya, adding Russian President Vladimir Putin as a step toward bringing the Kremlin to Russia #39;s war-torn region to the Kremlin-backed war. Chechen warlord Shamkhazakh\n"]}]}]}